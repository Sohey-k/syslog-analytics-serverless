# è¨­è¨ˆæ›¸

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå:** Juniper Syslog Analytics Serverless  
**ä½œæˆæ—¥:** 2025-12-30    
**æœ€çµ‚æ›´æ–°:** 2026-01-01 (Phase 2: CloudFrontå¯¾å¿œ)  
**å¯¾å¿œè¦ä»¶å®šç¾©æ›¸:** requirements.md v2.0

---

## 1. ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆè¨­è¨ˆ

### 1.1 å…¨ä½“ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS Account                          â”‚
â”‚                  (ap-northeast-1)                       â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  S3 Bucket: syslog-input-bucket               â”‚    â”‚
â”‚  â”‚  â”œâ”€ raw/YYYY-MM-DD/*.zip                      â”‚    â”‚
â”‚  â”‚  â””â”€ Versioning: Disabled                      â”‚    â”‚
â”‚  â”‚     Lifecycle: 30æ—¥å¾Œå‰Šé™¤                      â”‚    â”‚
â”‚  â”‚     Encryption: SSE-S3                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚ Event: s3:ObjectCreated:Put            â”‚
â”‚               â”‚ Filter: prefix=raw/, suffix=.zip       â”‚
â”‚               â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Lambda Function: syslog-parser-function      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚  â”‚ Runtime: python3.11                     â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Memory: 512MB                           â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Timeout: 300s (5åˆ†)                     â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Handler: lambda_function.lambda_handler â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Package: ZIPå½¢å¼ (æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿)     â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Environment Variables:                  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚   - DYNAMODB_TABLE: stats-table-name   â”‚ â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â”‚                                                â”‚    â”‚
â”‚  â”‚  IAM Role: lambda-execution-role              â”‚    â”‚
â”‚  â”‚  â”œâ”€ S3 GetObject (input-bucket)               â”‚    â”‚
â”‚  â”‚  â”œâ”€ DynamoDB PutItem (stats-table)            â”‚    â”‚
â”‚  â”‚  â””â”€ CloudWatch Logs (CreateLogGroupç­‰)        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚ boto3.Table.put_item()                 â”‚
â”‚               â†“                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  DynamoDB Table: syslog-hourly-stats          â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚  â”‚ Table Class: Standard                   â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Billing Mode: PAY_PER_REQUEST           â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Partition Key: log_date (S)             â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Sort Key: hour (S)                      â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Point-in-time Recovery: Disabled        â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Encryption: AWS Managed (default)       â”‚ â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚                                         â”‚
â”‚               â†“ (Phase 3å®Ÿè£…)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  S3 Bucket: syslog-output-bucket              â”‚    â”‚
â”‚  â”‚  â”œâ”€ index.html (Dashboard)                    â”‚    â”‚
â”‚  â”‚  â”œâ”€ data/YYYY-MM-DD.json (çµ±è¨ˆãƒ‡ãƒ¼ã‚¿)          â”‚    â”‚
â”‚  â”‚  â””â”€ Public Access: BLOCKED (OACçµŒç”±ã®ã¿)      â”‚    â”‚
â”‚  â”‚     Encryption: SSE-S3                        â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚ Origin Access Control (OAC)            â”‚
â”‚               â”‚                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  CloudFront Distribution (HTTPS)               â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚
â”‚  â”‚  â”‚ Domain: d1xxxxx.cloudfront.net          â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ SSL: CloudFront Default Certificate     â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Price Class: 200 (ç±³å›½,æ¬§å·,ã‚¢ã‚¸ã‚¢)      â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Cache: index.html(1h), data/*.json(5m)  â”‚ â”‚    â”‚
â”‚  â”‚  â”‚ Viewer Protocol: redirect-to-https      â”‚ â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚               â”‚ HTTPS                                   â”‚
â”‚               â†“                                         â”‚
â”‚         [ User Browser ]                                â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  CloudWatch Logs                               â”‚    â”‚
â”‚  â”‚  â””â”€ /aws/lambda/syslog-parser-function        â”‚    â”‚
â”‚  â”‚     Retention: 7 days                         â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ã€å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã€‘
User PC (WSL2)
  â”œâ”€ Syslog Generator (Python)
  â”œâ”€ AWS CLI
  â””â”€ Terraform
```

### 1.2 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼è©³ç´°

```
ã€ãƒ•ãƒ­ãƒ¼1: ãƒ­ã‚°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€œè§£æã€‘

Step 1: ãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œ
  User: AWS CLIå®Ÿè¡Œ
  $ aws s3 cp 10.zip s3://syslog-input-bucket/raw/2025-04-28/
  
  Duration: ~5ç§’ (10MB ZIP)

Step 2: S3ã‚¤ãƒ™ãƒ³ãƒˆç™ºç«
  Event Type: s3:ObjectCreated:Put
  Event Payload:
  {
    "Records": [{
      "eventName": "ObjectCreated:Put",
      "s3": {
        "bucket": {"name": "syslog-input-bucket"},
        "object": {
          "key": "raw/2025-04-28/10.zip",
          "size": 10485760
        }
      }
    }]
  }
  
  Duration: ~100ms (ã‚¤ãƒ™ãƒ³ãƒˆä¼æ’­)

Step 3: Lambdaèµ·å‹•
  Invocation Type: Event (éåŒæœŸ)
  Trigger: S3ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥
  Cold Start: åˆå›ã®ã¿ ~3ç§’
  Warm Start: ~100ms
  
Step 4: Lambdaå‡¦ç†å®Ÿè¡Œ
  4-1. S3ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (5ç§’)
       boto3.download_file()
       /tmp/input.zip (10MB)
  
  4-2. ZIPè§£å‡ (2ç§’)
       zipfile.ZipFile.extractall()
       /tmp/extracted/10.csv (10MB)
  
  4-3. CSVè§£æ (20ç§’)
       csv.DictReader()
       50,000è¡Œã‚’ãƒ¡ãƒ¢ãƒªä¸Šã§å‡¦ç†
       CRITICAL/WARNING ãƒ•ã‚£ãƒ«ã‚¿
       æ™‚é–“åˆ¥é›†è¨ˆ
       
       ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: ~200MB
       
  4-4. DynamoDBæ›¸ãè¾¼ã¿ (3ç§’)
       24å›ã®put_item() (æ™‚é–“ã”ã¨)
       
  Total Duration: ~30ç§’ (10MBãƒ•ã‚¡ã‚¤ãƒ«)
  
Step 5: CloudWatch Logså‡ºåŠ›
  Log Group: /aws/lambda/syslog-parser-function
  Log Stream: 2025/04/28/[$LATEST]xxxxx
  
  ãƒ­ã‚°å†…å®¹:
  - å‡¦ç†é–‹å§‹ãƒ­ã‚°
  - S3ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†
  - CSVè§£æçµ±è¨ˆï¼ˆCRITICAL: Xä»¶, WARNING: Yä»¶ï¼‰
  - DynamoDBæ›¸ãè¾¼ã¿å®Œäº†
  - å‡¦ç†å®Œäº†ï¼ˆæ‰€è¦æ™‚é–“ï¼‰
```

---

## 2. Lambdaé–¢æ•°è©³ç´°è¨­è¨ˆ

### 2.1 é–¢æ•°æ§‹æˆ

```
lambda/syslog_parser/
â”œâ”€â”€ lambda_function.py    # ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
â””â”€â”€ requirements.txt      # ç©ºãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆæ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ï¼‰
```

### 2.2 lambda_function.py å®Ÿè£…ä»•æ§˜

```python
"""
Juniper Syslog Parser Lambda Function

S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸZIPå½¢å¼ã®Syslogã‚’è§£æã—ã€
CRITICAL/WARNING ãƒ­ã‚°ã‚’æ™‚é–“åˆ¥ã«é›†è¨ˆã—ã¦DynamoDBã«ä¿å­˜ã™ã‚‹ã€‚

Author: Sohey
Created: 2025-12-30
"""

import os
import json
import boto3
import zipfile
import csv
from datetime import datetime
from collections import defaultdict
from pathlib import Path

# ç’°å¢ƒå¤‰æ•°
DYNAMODB_TABLE = os.environ['DYNAMODB_TABLE']

# AWSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã§å†åˆ©ç”¨ï¼‰
s3_client = boto3.client('s3')
dynamodb = boto3.resource('dynamodb')
table = dynamodb.Table(DYNAMODB_TABLE)

def lambda_handler(event, context):
    """
    ãƒ¡ã‚¤ãƒ³ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
    
    Args:
        event (dict): S3ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥
            {
              "Records": [{
                "s3": {
                  "bucket": {"name": "bucket-name"},
                  "object": {"key": "raw/2025-04-28/10.zip"}
                }
              }]
            }
        context (LambdaContext): Lambdaå®Ÿè¡Œã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    
    Returns:
        dict: å‡¦ç†çµæœ
            {
              'statusCode': 200,
              'body': 'Successfully processed ...'
            }
    
    Raises:
        Exception: S3ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ã€ZIPè§£å‡ã‚¨ãƒ©ãƒ¼ç­‰
    """
    try:
        print("=== Lambda Function Started ===")
        
        # 1. ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰S3æƒ…å ±å–å¾—
        bucket, key = extract_s3_info(event)
        print(f"Processing: s3://{bucket}/{key}")
        
        # 2. ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        local_zip = download_zip(bucket, key)
        print(f"Downloaded to: {local_zip}")
        
        # 3. CSVè§£å‡
        csv_path = extract_csv(local_zip)
        print(f"Extracted to: {csv_path}")
        
        # 4. CSVè§£æ
        stats = parse_csv(csv_path)
        print(f"Parsed log_date: {stats['log_date']}")
        print(f"Total hours: {len(stats['hourly_stats'])}")
        
        # 5. DynamoDBä¿å­˜
        save_to_dynamodb(stats, key)
        print(f"Saved to DynamoDB: {DYNAMODB_TABLE}")
        
        print("=== Lambda Function Completed ===")
        
        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': f'Successfully processed {key}',
                'log_date': stats['log_date'],
                'total_hours': len(stats['hourly_stats'])
            })
        }
        
    except Exception as e:
        print(f"ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

def extract_s3_info(event):
    """
    S3ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰ãƒã‚±ãƒƒãƒˆåã¨ã‚­ãƒ¼ã‚’æŠ½å‡º
    
    Args:
        event (dict): S3ã‚¤ãƒ™ãƒ³ãƒˆ
    
    Returns:
        tuple: (bucket_name, object_key)
    """
    record = event['Records'][0]
    bucket = record['s3']['bucket']['name']
    key = record['s3']['object']['key']
    return bucket, key

def download_zip(bucket, key):
    """
    S3ã‹ã‚‰ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    
    Args:
        bucket (str): S3ãƒã‚±ãƒƒãƒˆå
        key (str): S3ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼
    
    Returns:
        str: ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
    local_path = '/tmp/input.zip'
    s3_client.download_file(bucket, key, local_path)
    return local_path

def extract_csv(zip_path):
    """
    ZIPã‚’è§£å‡ã—ã¦CSVãƒ‘ã‚¹ã‚’è¿”ã™
    
    Args:
        zip_path (str): ZIPãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    
    Returns:
        str: CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    
    Raises:
        Exception: ZIPå†…ã«CSVãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    """
    extract_dir = '/tmp/extracted'
    Path(extract_dir).mkdir(exist_ok=True)
    
    with zipfile.ZipFile(zip_path, 'r') as z:
        z.extractall(extract_dir)
        csv_files = [f for f in z.namelist() if f.endswith('.csv')]
        
        if not csv_files:
            raise Exception("No CSV file found in ZIP")
        
        return f"{extract_dir}/{csv_files[0]}"

def parse_csv(csv_path):
    """
    CSVã‚’è§£æã—ã¦æ™‚é–“åˆ¥çµ±è¨ˆã‚’ä½œæˆ
    
    Args:
        csv_path (str): CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    
    Returns:
        dict: {
            'log_date': '2025-04-28',
            'hostname': 'srx-fw01',
            'hourly_stats': {
                '10:00': {'CRITICAL': 15, 'WARNING': 43},
                '11:00': {'CRITICAL': 8, 'WARNING': 37},
                ...
            }
        }
    
    å‡¦ç†å†…å®¹:
        1. CSVèª­ã¿è¾¼ã¿ (csv.DictReader)
        2. Timestamp ã‹ã‚‰æ™‚é–“æŠ½å‡º (æ–‡å­—åˆ—ã‚¹ãƒ©ã‚¤ã‚¹)
        3. Severity ãƒ•ã‚£ãƒ«ã‚¿ (CRITICAL, WARNING)
        4. æ™‚é–“åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ (defaultdict)
    """
    stats = defaultdict(lambda: {'CRITICAL': 0, 'WARNING': 0})
    log_date = None
    hostname = None
    total_rows = 0
    filtered_rows = 0
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        
        for row in reader:
            total_rows += 1
            
            # åˆå›ã®ã¿æ—¥ä»˜ã¨ãƒ›ã‚¹ãƒˆåå–å¾—
            if not log_date:
                # "2025-04-28T10:15:30Z" â†’ "2025-04-28"
                log_date = row['Timestamp'][:10]
                hostname = row['Hostname']
            
            severity = row['Severity']
            
            # CRITICAL/WARNING ã®ã¿ã‚«ã‚¦ãƒ³ãƒˆ
            if severity in ['CRITICAL', 'WARNING']:
                filtered_rows += 1
                # "2025-04-28T10:15:30Z" â†’ "10:00"
                hour = row['Timestamp'][11:13] + ':00'
                stats[hour][severity] += 1
    
    print(f"CSV Statistics:")
    print(f"  Total rows: {total_rows}")
    print(f"  Filtered rows (CRITICAL/WARNING): {filtered_rows}")
    print(f"  Filter ratio: {filtered_rows/total_rows*100:.1f}%")
    
    return {
        'log_date': log_date,
        'hostname': hostname,
        'hourly_stats': dict(stats)
    }

def save_to_dynamodb(stats, file_name):
    """
    DynamoDBã«æ™‚é–“åˆ¥çµ±è¨ˆã‚’ä¿å­˜
    
    Args:
        stats (dict): parse_csv()ã®è¿”ã‚Šå€¤
        file_name (str): S3ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼
    
    DynamoDBã‚¹ã‚­ãƒ¼ãƒ:
        PK: log_date (String)
        SK: hour (String)
        Attributes:
            - critical_count (Number)
            - warning_count (Number)
            - total_count (Number)
            - hostname (String)
            - processed_at (String)
            - file_name (String)
    """
    log_date = stats['log_date']
    hostname = stats['hostname']
    processed_at = datetime.utcnow().isoformat() + 'Z'
    
    saved_count = 0
    
    # æ™‚é–“ã”ã¨ã«ã‚¢ã‚¤ãƒ†ãƒ ä½œæˆ
    for hour, counts in stats['hourly_stats'].items():
        critical = counts['CRITICAL']
        warning = counts['WARNING']
        total = critical + warning
        
        table.put_item(Item={
            'log_date': log_date,
            'hour': hour,
            'critical_count': critical,
            'warning_count': warning,
            'total_count': total,
            'hostname': hostname,
            'processed_at': processed_at,
            'file_name': file_name
        })
        
        saved_count += 1
    
    print(f"DynamoDB: Saved {saved_count} items")
```

### 2.3 Lambdaè¨­å®šå€¤

| è¨­å®šé …ç›® | å€¤ | ç†ç”± |
|---------|---|------|
| Runtime | python3.11 | æœ€æ–°ã€é«˜é€Ÿ |
| Memory | 512MB | CSV 50,000è¡Œå‡¦ç†ã«å¿…è¦ |
| Timeout | 300ç§’ (5åˆ†) | 100MBãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä½™è£• |
| Ephemeral Storage | 512MB (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) | ZIP+CSV ã§æœ€å¤§200MB |
| Architecture | x86_64 | äº’æ›æ€§é‡è¦– |
| Reserved Concurrency | ãªã— | åŒæ™‚å®Ÿè¡Œåˆ¶é™ãªã— |

### 2.4 ç’°å¢ƒå¤‰æ•°

| å¤‰æ•°å | å€¤ | èª¬æ˜ |
|-------|---|------|
| DYNAMODB_TABLE | `syslog-hourly-stats` | DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«å |

---

## 3. DynamoDBè¨­è¨ˆ

### 3.1 ãƒ†ãƒ¼ãƒ–ãƒ«ä»•æ§˜

```
ãƒ†ãƒ¼ãƒ–ãƒ«å: syslog-hourly-stats
ãƒªãƒ¼ã‚¸ãƒ§ãƒ³: ap-northeast-1
Table Class: Standard
Billing Mode: PAY_PER_REQUEST (ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰)

ã‚­ãƒ¼è¨­è¨ˆ:
  Partition Key: log_date (String)
    å½¢å¼: YYYY-MM-DD
    ä¾‹: "2025-04-28"
  
  Sort Key: hour (String)
    å½¢å¼: HH:00
    ä¾‹: "10:00"

å±æ€§:
  - log_date (S) [PK]
  - hour (S) [SK]
  - critical_count (N)
  - warning_count (N)
  - total_count (N)
  - hostname (S)
  - processed_at (S)
  - file_name (S)

ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: ãªã—

è¨­å®š:
  - Point-in-time Recovery: ç„¡åŠ¹
  - Encryption: AWS Managed
  - Time to Live (TTL): æœªè¨­å®š
  - Stream: ç„¡åŠ¹
```

### 3.2 ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³

**ãƒ‘ã‚¿ãƒ¼ãƒ³1: ç‰¹å®šæ—¥ã®å…¨æ™‚é–“ãƒ‡ãƒ¼ã‚¿å–å¾—**

```python
response = table.query(
    KeyConditionExpression=Key('log_date').eq('2025-04-28')
)

# è¿”å´ãƒ‡ãƒ¼ã‚¿: 24ä»¶ (00:00 ~ 23:00)
```

**ãƒ‘ã‚¿ãƒ¼ãƒ³2: ç‰¹å®šæ™‚åˆ»ã®ãƒ‡ãƒ¼ã‚¿å–å¾—**

```python
response = table.query(
    KeyConditionExpression=Key('log_date').eq('2025-04-28') & Key('hour').eq('10:00')
)

# è¿”å´ãƒ‡ãƒ¼ã‚¿: 1ä»¶
```

**ãƒ‘ã‚¿ãƒ¼ãƒ³3: æ™‚é–“ç¯„å›²ã§ã®ãƒ‡ãƒ¼ã‚¿å–å¾—**

```python
response = table.query(
    KeyConditionExpression=Key('log_date').eq('2025-04-28') & Key('hour').between('10:00', '12:00')
)

# è¿”å´ãƒ‡ãƒ¼ã‚¿: 3ä»¶ (10:00, 11:00, 12:00)
```

### 3.3 å®¹é‡è¦‹ç©ã‚‚ã‚Š

```
1ã‚¢ã‚¤ãƒ†ãƒ ã®ã‚µã‚¤ã‚º:
  log_date: 10 bytes
  hour: 5 bytes
  critical_count: 8 bytes
  warning_count: 8 bytes
  total_count: 8 bytes
  hostname: 10 bytes
  processed_at: 25 bytes
  file_name: 30 bytes
  
  åˆè¨ˆ: ç´„ 100 bytes

1æ—¥åˆ†: 100 bytes Ã— 24æ™‚é–“ = 2.4 KB
1ãƒ¶æœˆåˆ†: 2.4 KB Ã— 30æ—¥ = 72 KB
1å¹´åˆ†: 72 KB Ã— 12ãƒ¶æœˆ = 864 KB

â†’ ç„¡æ–™æ  25GB ã«å¯¾ã—ã¦ååˆ†å°ã•ã„
```

---

## 4. S3ãƒã‚±ãƒƒãƒˆè¨­è¨ˆ

### 4.1 å…¥åŠ›ãƒã‚±ãƒƒãƒˆ (syslog-input-bucket)

```
Bucket Name: syslog-input-{AWS_ACCOUNT_ID}
Region: ap-northeast-1

Versioning: ç„¡åŠ¹
Encryption: SSE-S3 (AES-256)
Public Access: ã™ã¹ã¦ãƒ–ãƒ­ãƒƒã‚¯

Lifecycle Rule:
  Name: delete-old-logs
  Filter: Prefix = raw/
  Action: Delete after 30 days
  Status: Enabled

Event Notification:
  Event Type: s3:ObjectCreated:Put
  Filter:
    Prefix: raw/
    Suffix: .zip
  Destination: Lambda Function (syslog-parser-function)

ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :
  raw/
  â””â”€â”€ YYYY-MM-DD/
      â”œâ”€â”€ 00.zip
      â”œâ”€â”€ 01.zip
      ...
      â””â”€â”€ 23.zip
```

### 4.2 å‡ºåŠ›ãƒã‚±ãƒƒãƒˆ (syslog-output-bucket) - Phase 3

```
Bucket Name: syslog-output-{AWS_ACCOUNT_ID}
Region: ap-northeast-1

Versioning: ç„¡åŠ¹
Encryption: SSE-S3
Public Access: 
  - BlockPublicAcls: true
  - IgnorePublicAcls: true
  - BlockPublicPolicy: false (é™çš„ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°ç”¨)
  - RestrictPublicBuckets: false

Static Website Hosting:
  Enabled: Yes
  Index Document: dashboard/index.html
  Error Document: error.html

Bucket Policy:
  Allow s3:GetObject for * (å…¬é–‹èª­ã¿å–ã‚Š)

ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ :
  dashboard/
  â””â”€â”€ index.html
```

---

## 5. IAMè¨­è¨ˆ

### 5.1 Lambdaå®Ÿè¡Œãƒ­ãƒ¼ãƒ«

```hcl
# Terraformå®šç¾©

resource "aws_iam_role" "lambda_exec" {
  name = "syslog-parser-lambda-role"
  
  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Action = "sts:AssumeRole"
      Effect = "Allow"
      Principal = {
        Service = "lambda.amazonaws.com"
      }
    }]
  })
}

resource "aws_iam_role_policy" "lambda_policy" {
  role = aws_iam_role.lambda_exec.id
  name = "syslog-parser-lambda-policy"
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      # S3èª­ã¿å–ã‚Šï¼ˆå…¥åŠ›ãƒã‚±ãƒƒãƒˆã®ã¿ï¼‰
      {
        Effect = "Allow"
        Action = [
          "s3:GetObject"
        ]
        Resource = "${aws_s3_bucket.input.arn}/*"
      },
      
      # DynamoDBæ›¸ãè¾¼ã¿ï¼ˆstatsãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿ï¼‰
      {
        Effect = "Allow"
        Action = [
          "dynamodb:PutItem"
        ]
        Resource = aws_dynamodb_table.stats.arn
      },
      
      # CloudWatch Logsï¼ˆå…¨Lambdaæ¨™æº–ï¼‰
      {
        Effect = "Allow"
        Action = [
          "logs:CreateLogGroup",
          "logs:CreateLogStream",
          "logs:PutLogEvents"
        ]
        Resource = "arn:aws:logs:*:*:*"
      }
    ]
  })
}
```

### 5.2 æœ€å°æ¨©é™ã®åŸå‰‡

**è¨±å¯ã—ã¦ã„ãªã„æ“ä½œ:**
- S3: DeleteObject, PutObject (ä¸è¦)
- DynamoDB: DeleteItem, UpdateItem, Scan (ä¸è¦)
- Lambda: InvokeFunction (ä¸è¦)
- ä»–ã‚µãƒ¼ãƒ“ã‚¹: ã™ã¹ã¦æ‹’å¦

---

## 6. Terraformãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
terraform/
â”œâ”€â”€ main.tf              # Providerã€Backendè¨­å®š
â”œâ”€â”€ variables.tf         # å¤‰æ•°å®šç¾©
â”œâ”€â”€ outputs.tf           # å‡ºåŠ›å€¤
â”œâ”€â”€ s3.tf               # S3ãƒã‚±ãƒƒãƒˆ
â”œâ”€â”€ lambda.tf           # Lambdaé–¢æ•°
â”œâ”€â”€ iam.tf              # IAMãƒ­ãƒ¼ãƒ«ãƒ»ãƒãƒªã‚·ãƒ¼
â”œâ”€â”€ dynamodb.tf         # DynamoDBãƒ†ãƒ¼ãƒ–ãƒ«
â””â”€â”€ cloudwatch.tf       # CloudWatch Logs

å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¹å‰²:
  - main.tf: å…±é€šè¨­å®šï¼ˆprovider, regionç­‰ï¼‰
  - s3.tf: å…¥åŠ›/å‡ºåŠ›ãƒã‚±ãƒƒãƒˆã€ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥
  - lambda.tf: é–¢æ•°å®šç¾©ã€ãƒˆãƒªã‚¬ãƒ¼è¨­å®š
  - iam.tf: æœ€å°æ¨©é™IAMãƒ­ãƒ¼ãƒ«
  - dynamodb.tf: ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©
  - cloudwatch.tf: ãƒ­ã‚°ä¿æŒæœŸé–“è¨­å®š
```

---

## 7. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è¨­è¨ˆ

### 7.1 Lambdaå†…ã‚¨ãƒ©ãƒ¼å‡¦ç†

| ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ | å‡¦ç† | CloudWatchå‡ºåŠ› |
|----------|-----|---------------|
| S3ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ | ä¾‹å¤–ã‚¹ãƒ­ãƒ¼ | ERROR + traceback |
| ZIPè§£å‡ã‚¨ãƒ©ãƒ¼ | ä¾‹å¤–ã‚¹ãƒ­ãƒ¼ | ERROR + traceback |
| CSVå½¢å¼ã‚¨ãƒ©ãƒ¼ | ä¾‹å¤–ã‚¹ãƒ­ãƒ¼ | ERROR + è¡Œç•ªå· |
| DynamoDBæ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼ | ä¾‹å¤–ã‚¹ãƒ­ãƒ¼ | ERROR + Itemæƒ…å ± |

```python
try:
    # å‡¦ç†
except Exception as e:
    print(f"ERROR: {str(e)}")
    import traceback
    traceback.print_exc()
    raise  # Lambda ãŒå¤±æ•—ã¨ã—ã¦è¨˜éŒ²
```

### 7.2 ãƒªãƒˆãƒ©ã‚¤æˆ¦ç•¥

- **Lambda:** S3ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥ã¯è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ï¼ˆæœ€å¤§2å›ï¼‰
- **DynamoDB:** boto3ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒªãƒˆãƒ©ã‚¤ï¼ˆExponential Backoffï¼‰

---

## 8. ç›£è¦–ãƒ»ãƒ­ã‚°è¨­è¨ˆ

### 8.1 CloudWatch Logs

```
Log Group: /aws/lambda/syslog-parser-function
Retention: 7 days
Encryption: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ (AES-256)

ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«:
  - INFO: å‡¦ç†é–‹å§‹/å®Œäº†ã€çµ±è¨ˆæƒ…å ±
  - ERROR: ä¾‹å¤–ç™ºç”Ÿæ™‚

ã‚µãƒ³ãƒ—ãƒ«ãƒ­ã‚°:
[INFO] === Lambda Function Started ===
[INFO] Processing: s3://syslog-input-123456/raw/2025-04-28/10.zip
[INFO] Downloaded to: /tmp/input.zip
[INFO] Extracted to: /tmp/extracted/10.csv
[INFO] CSV Statistics:
[INFO]   Total rows: 50400
[INFO]   Filtered rows (CRITICAL/WARNING): 5040
[INFO]   Filter ratio: 10.0%
[INFO] Parsed log_date: 2025-04-28
[INFO] Total hours: 24
[INFO] DynamoDB: Saved 24 items
[INFO] === Lambda Function Completed ===
```

### 8.2 CloudWatch Metricsï¼ˆè‡ªå‹•åé›†ï¼‰

- Lambda Invocations
- Lambda Duration
- Lambda Errors
- Lambda Throttles

### 8.3 ã‚¢ãƒ©ãƒ¼ãƒˆè¨­è¨ˆï¼ˆPhase 3ï¼‰

```
ã‚¢ãƒ©ãƒ¼ãƒˆ1: Lambdaå®Ÿè¡Œã‚¨ãƒ©ãƒ¼
  Metric: Errors
  Threshold: > 0
  Period: 5åˆ†
  Action: SNSé€šçŸ¥

ã‚¢ãƒ©ãƒ¼ãƒˆ2: Lambdaå®Ÿè¡Œæ™‚é–“è¶…é
  Metric: Duration
  Threshold: > 240ç§’ (4åˆ†)
  Period: 5åˆ†
  Action: SNSé€šçŸ¥
```

---

## 9. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­è¨ˆ

### 9.1 ãƒ‡ãƒ¼ã‚¿ä¿è­·

| ãƒ‡ãƒ¼ã‚¿ | ä¿è­·æ–¹æ³• |
|-------|---------|
| S3 (è»¢é€ä¸­) | HTTPSå¼·åˆ¶ |
| S3 (ä¿ç®¡æ™‚) | SSE-S3 (AES-256) |
| DynamoDB (è»¢é€ä¸­) | HTTPS (boto3ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ) |
| DynamoDB (ä¿ç®¡æ™‚) | AWS Managed Key |
| Lambdaç’°å¢ƒå¤‰æ•° | æš—å·åŒ–ãªã—ï¼ˆæ©Ÿå¯†æƒ…å ±ãªã—ï¼‰ |

### 9.2 ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡

```
Lambda â†’ S3: 
  âœ“ GetObject (å…¥åŠ›ãƒã‚±ãƒƒãƒˆã®ã¿)
  âœ— PutObject, DeleteObject

Lambda â†’ DynamoDB:
  âœ“ PutItem (statsãƒ†ãƒ¼ãƒ–ãƒ«ã®ã¿)
  âœ— DeleteItem, UpdateItem, Scan

User â†’ S3:
  AWS CLIçµŒç”± (IAM Userèªè¨¼)
```

### 9.3 ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­è¨ˆ

- **Lambda:** VPCä¸è¦ï¼ˆãƒ‘ãƒ–ãƒªãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã®ã¿ã‚¢ã‚¯ã‚»ã‚¹ï¼‰
- **S3:** VPC Endpointä¸è¦ï¼ˆç„¡æ–™æ å„ªå…ˆï¼‰
- **DynamoDB:** VPC Endpointä¸è¦

---

## 10. ã‚³ã‚¹ãƒˆè¨­è¨ˆ

### 10.1 æœˆé–“ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Šï¼ˆ30æ—¥é–“ï¼‰

```
ã€å‰æã€‘
- 1æ—¥ã‚ãŸã‚Š24ãƒ•ã‚¡ã‚¤ãƒ« (10MB Ã— 24)
- Lambdaå®Ÿè¡Œ: 30ç§’/ãƒ•ã‚¡ã‚¤ãƒ«
- DynamoDBæ›¸ãè¾¼ã¿: 24ä»¶/ãƒ•ã‚¡ã‚¤ãƒ«
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¢ã‚¯ã‚»ã‚¹: 10å›/æ—¥

ã€Lambdaã€‘
  å®Ÿè¡Œå›æ•°: 24 Ã— 30 = 720å›/æœˆ
  ç„¡æ–™æ : 100ä¸‡å›/æœˆ
  â†’ $0 âœ…

  å®Ÿè¡Œæ™‚é–“: 720å› Ã— 30ç§’ Ã— 512MB = 10,800 GBç§’
  ç„¡æ–™æ : 400,000 GBç§’/æœˆ
  â†’ $0 âœ…

ã€S3ã€‘
  Storage: 240MB (10MB Ã— 24ãƒ•ã‚¡ã‚¤ãƒ«)
  ç„¡æ–™æ : 5GB
  â†’ $0 âœ…
  
  PUT: 720å›/æœˆ + 30å›(Lambdaâ†’Output)
  ç„¡æ–™æ : 2,000å›/æœˆ
  â†’ $0 âœ…
  
  GET (Lambda): 720å›/æœˆ
  ç„¡æ–™æ : 20,000å›/æœˆ
  â†’ $0 âœ…

ã€DynamoDBã€‘
  Storage: 72 KB/æœˆ
  ç„¡æ–™æ : 25GB
  â†’ $0 âœ…
  
  Write: 720ãƒ•ã‚¡ã‚¤ãƒ« Ã— 24ä»¶ = 17,280 WCU
  ç„¡æ–™æ : 200ä¸‡ WCU/æœˆ
  â†’ $0 âœ…

ã€CloudFrontã€‘ğŸ†•
  HTTPS ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: 300å›/æœˆ (10å›/æ—¥ Ã— 30æ—¥)
  ç„¡æ–™æ : 1,000ä¸‡å›/æœˆ
  â†’ $0 âœ…
  
  ãƒ‡ãƒ¼ã‚¿è»¢é€: 15MB/æœˆ (50KB Ã— 300å›)
  ç„¡æ–™æ : 50GB/æœˆ (æœ€åˆã®12ãƒ¶æœˆ)
  â†’ $0 âœ…
  
  13ãƒ¶æœˆç›®ä»¥é™:
  15MB Ã— $0.114/GB = $0.0017/æœˆ (0.17å††)

åˆè¨ˆ: 
  æœ€åˆã®12ãƒ¶æœˆ: $0/æœˆ ğŸ‰
  13ãƒ¶æœˆç›®ä»¥é™: ~$0.002/æœˆ (0.2å††)
```

### 10.2 ã‚³ã‚¹ãƒˆæœ€é©åŒ–æ–½ç­–

- S3 Lifecycle: 30æ—¥å¾Œè‡ªå‹•å‰Šé™¤
- DynamoDB: ã‚ªãƒ³ãƒ‡ãƒãƒ³ãƒ‰èª²é‡‘ï¼ˆå¾…æ©Ÿã‚³ã‚¹ãƒˆã‚¼ãƒ­ï¼‰
- Lambda: æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã¿ï¼ˆLayerä¸è¦ï¼‰
- CloudWatch Logs: 7æ—¥ä¿æŒï¼ˆæœ€å°é™ï¼‰
- **CloudFront: Price Class 200ï¼ˆæ—¥æœ¬å«ã‚€ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«é…ä¿¡ã¯ä¸è¦ï¼‰** ğŸ†•
- **S3 OAC: S3â†’CloudFrontè»¢é€ã¯ç„¡æ–™** ğŸ†•

---

## 11. ãƒ†ã‚¹ãƒˆè¨­è¨ˆ

### 11.1 ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

```python
# lambda/syslog_parser/tests/test_parser.py

import unittest
from lambda_function import extract_s3_info, parse_csv

class TestLambdaFunction(unittest.TestCase):
    
    def test_extract_s3_info(self):
        event = {
            'Records': [{
                's3': {
                    'bucket': {'name': 'test-bucket'},
                    'object': {'key': 'raw/2025-04-28/10.zip'}
                }
            }]
        }
        bucket, key = extract_s3_info(event)
        self.assertEqual(bucket, 'test-bucket')
        self.assertEqual(key, 'raw/2025-04-28/10.zip')
    
    def test_parse_csv(self):
        # ã‚µãƒ³ãƒ—ãƒ«CSVã‚’ä½¿ã£ã¦ãƒ†ã‚¹ãƒˆ
        csv_path = './test_data/sample.csv'
        stats = parse_csv(csv_path)
        
        self.assertIn('log_date', stats)
        self.assertIn('hostname', stats)
        self.assertIn('hourly_stats', stats)

if __name__ == '__main__':
    unittest.main()
```

### 11.2 çµ±åˆãƒ†ã‚¹ãƒˆ

```bash
# E2Eãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

#!/bin/bash

# 1. ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
python generator/generate.py -r 2100 -o ./test_data

# 2. S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
aws s3 cp test_data/10.zip s3://syslog-input-bucket/raw/2025-04-28/

# 3. Lambdaå®Ÿè¡Œç¢ºèªï¼ˆCloudWatch Logsç›£è¦–ï¼‰
aws logs tail /aws/lambda/syslog-parser-function --follow

# 4. DynamoDBç¢ºèª
aws dynamodb query \
  --table-name syslog-hourly-stats \
  --key-condition-expression "log_date = :date" \
  --expression-attribute-values '{":date":{"S":"2025-04-28"}}'

# 5. çµæœæ¤œè¨¼
# - 24ä»¶ã®ã‚¢ã‚¤ãƒ†ãƒ ãŒå­˜åœ¨ã™ã‚‹ã“ã¨
# - CRITICAL/WARNING ã®ã‚«ã‚¦ãƒ³ãƒˆãŒæ­£ç¢ºã§ã‚ã‚‹ã“ã¨
```

---

## 12. ãƒ‡ãƒ—ãƒ­ã‚¤è¨­è¨ˆ

### 12.1 ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ•ãƒ­ãƒ¼

```
ã€ãƒ­ãƒ¼ã‚«ãƒ« â†’ AWSã€‘

1. TerraformåˆæœŸåŒ–
   $ cd terraform
   $ terraform init

2. å¤‰æ•°è¨­å®š
   $ cp terraform.tfvars.example terraform.tfvars
   $ vi terraform.tfvars
   
   aws_region = "ap-northeast-1"
   project_name = "syslog-analytics"

3. ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ—ãƒ©ãƒ³ç¢ºèª
   $ terraform plan

4. ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ
   $ terraform apply

5. å‹•ä½œç¢ºèª
   $ aws s3 cp test.zip s3://...
```

### 12.2 CI/CDè¨­è¨ˆï¼ˆGitHub Actionsï¼‰

```yaml
# .github/workflows/terraform.yml

name: Terraform

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  terraform:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.6.0
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-1
      
      - name: Terraform Init
        run: terraform init
        working-directory: ./terraform
      
      - name: Terraform Format Check
        run: terraform fmt -check
        working-directory: ./terraform
      
      - name: Terraform Validate
        run: terraform validate
        working-directory: ./terraform
      
      - name: Terraform Plan
        if: github.event_name == 'pull_request'
        run: terraform plan
        working-directory: ./terraform
      
      - name: Terraform Apply
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        run: terraform apply -auto-approve
        working-directory: ./terraform
```

---

## 13. é‹ç”¨è¨­è¨ˆ

### 13.1 æ—¥å¸¸é‹ç”¨

```
ã€æ—¥æ¬¡ã€‘
- CloudWatch Logsç¢ºèªï¼ˆã‚¨ãƒ©ãƒ¼ãŒãªã„ã‹ï¼‰
- DynamoDBå®¹é‡ç¢ºèªï¼ˆ25GBä»¥ä¸‹ã‹ï¼‰

ã€é€±æ¬¡ã€‘
- S3ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç¢ºèªï¼ˆLifecycleå‹•ä½œç¢ºèªï¼‰
- ã‚³ã‚¹ãƒˆç¢ºèªï¼ˆ$0ç¶­æŒã§ãã¦ã„ã‚‹ã‹ï¼‰

ã€æœˆæ¬¡ã€‘
- Lambdaå®Ÿè¡Œçµ±è¨ˆãƒ¬ãƒ“ãƒ¥ãƒ¼
- DynamoDBãƒ‡ãƒ¼ã‚¿ç²¾æŸ»
```

### 13.2 ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

| ç—‡çŠ¶ | åŸå›  | å¯¾å‡¦ |
|-----|-----|-----|
| Lambdaèµ·å‹•ã—ãªã„ | S3ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥æœªè¨­å®š | Terraformå†é©ç”¨ |
| DynamoDBæ›¸ãè¾¼ã¿å¤±æ•— | IAMæ¨©é™ä¸è¶³ | ãƒ­ãƒ¼ãƒ«ç¢ºèª |
| Lambda Timeout | ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºå¤§ | ãƒ¡ãƒ¢ãƒªå¢—åŠ  |
| S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•— | ãƒã‚±ãƒƒãƒˆåèª¤ã‚Š | ãƒã‚±ãƒƒãƒˆåç¢ºèª |

---

## 14. æ‹¡å¼µæ€§è¨­è¨ˆ

### 14.1 Phase 3: å¯è¦–åŒ–

```
Option Aå®Ÿè£…æ™‚:
  1. dashboard/index.html ä½œæˆ
  2. Chart.js ã§ã‚°ãƒ©ãƒ•æç”»
  3. DynamoDB APIçµŒç”±ã§ãƒ‡ãƒ¼ã‚¿å–å¾—
  4. S3é™çš„ãƒ›ã‚¹ãƒ†ã‚£ãƒ³ã‚°æœ‰åŠ¹åŒ–
```

### 14.2 Phase 4: å¤§å®¹é‡å¯¾å¿œ

```
100MBè¶…ã®ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ:
  1. Step Functionså°å…¥
  2. ãƒ•ã‚¡ã‚¤ãƒ«åˆ†å‰²å‡¦ç†
  3. ä¸¦åˆ—å®Ÿè¡Œ
  
ã¾ãŸã¯:
  1. Kinesis Data Firehose
  2. ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
```

---

**æ–‡æ›¸å±¥æ­´:**

| ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | æ—¥ä»˜ | å¤‰æ›´å†…å®¹ | ä½œæˆè€… |
|----------|-----|---------|-------|
| 1.0 | 2025-04-28 | åˆç‰ˆä½œæˆ | Sohey |